# ğŸ©º End-to-End Medical Chatbot (Generative AI)

An AI-powered medical chatbot built using Google Gemini 1.5 Pro, Pinecone Vector Store, HuggingFace Embeddings, and Flask.  
The chatbot can answer medical-related queries based on your custom knowledge base with Retrieval-Augmented Generation (RAG).  
Includes a simple chat UI for seamless interaction.  

## âœ¨ Features
- ğŸ”¹ Gemini 1.5 Pro as the LLM for accurate, context-aware responses  
- ğŸ”¹ Pinecone Vector Store for semantic search & retrieval  
- ğŸ”¹ HuggingFace sentence-transformers embeddings  
- ğŸ”¹ Flask backend with REST endpoints  
- ğŸ”¹ Simple chat UI (HTML/CSS/JS) for user interaction  
- ğŸ”¹ End-to-End RAG pipeline (Retriever + LLM)  

## ğŸ› ï¸ Tech Stack
- Python 3.9+  
- Flask (backend & API)  
- LangChain (RAG framework)  
- Pinecone (vector database)  
- HuggingFace (sentence-transformers/all-MiniLM-L6-v2 for embeddings)  
- Gemini 1.5 Pro (via Google Generative AI API)  
- HTML/CSS/JavaScript (UI)  

## âš™ï¸ Setup Instructions
```bash
# 1ï¸âƒ£ Clone repository
git clone https://github.com/<your-username>/End-to-End-Medical-Chatbot-Generative-AI.git
cd End-to-End-Medical-Chatbot-Generative-AI

# 2ï¸âƒ£ Create virtual environment
conda create -n mediora python=3.9 -y
conda activate mediora

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 4ï¸âƒ£ Create .env file (add your API keys)
echo "GOOGLE_API_KEY=your_google_gemini_api_key" >> .env
echo "PINECONE_API_KEY=your_pinecone_api_key" >> .env

# 5ï¸âƒ£ Start Flask server
python app.py
